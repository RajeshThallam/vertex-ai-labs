#! /home/dfisk/miniconda3/envs/ensemble/bin/python

import numpy as np
import os

import tensorflow as tf
from sklearn.model_selection import train_test_split

seed = 7
features = 4
samples = 1000

data_path = os.environ['HOME'] + "/Triton/ensemble/data/"
X_data = data_path + 'X.data.npy'
Y_data = data_path + 'Y.data.npy'

if (not os.path.exists(X_data)):
    print("Please run src/generate.py to create dummy data for modes")
else:
   X = np.load(X_data)
   Y = np.load(Y_data)

print("shape X " + str(X.shape))
print("shape Y " + str(Y.shape))

model_path = os.environ['HOME'] + "/Triton/ensemble/models/tf/1"

test_size = 0.33
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)


class_names = ['Zero', 'One']

model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])


model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])



model.fit(X_train, y_train, epochs=10)


test_loss, test_acc = model.evaluate(X_test,  y_test, verbose=2)

print('\nTest accuracy:', test_acc)

# creates /models/tf/model.tf/saved_model.pb
tf.saved_model.save(model, model_path + "model.savedmodel")






