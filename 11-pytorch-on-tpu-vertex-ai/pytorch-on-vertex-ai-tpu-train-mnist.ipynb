{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ecb70a-c170-4721-a895-c67cf1ff873a",
   "metadata": {},
   "source": [
    "# Training MNIST with PyTorch on TPU-VM using Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473acbc-9370-4de8-ad50-f4471495db2f",
   "metadata": {},
   "source": [
    "# Imports and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dae2be6-e296-45e5-9021-c116a96e72d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b78a856-4264-40b9-a71c-e8acb6b197f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d711f4-8b33-467b-bccc-c7d501ffcfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'rthallam-demo-project'\n",
    "BUCKET_NAME = \"cloud-ai-platform-2f444b6a-a742-444b-b91a-c7519f51bd77\"\n",
    "BUCKET_URI = f'gs://{BUCKET_NAME}'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ce760-396b-43c8-9022-d9551ba6c12e",
   "metadata": {},
   "source": [
    "## Create Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad233804-8b02-4249-bd45-77531f589a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "# adapted from https://github.com/pytorch/xla/blob/master/test/test_train_mp_mnist.py\n",
    "\n",
    "import args_parse\n",
    "\n",
    "FLAGS = args_parse.parse_common_options(\n",
    "    datadir='/tmp/mnist-data',\n",
    "    batch_size=128,\n",
    "    momentum=0.5,\n",
    "    lr=0.01,\n",
    "    target_accuracy=98.0,\n",
    "    num_epochs=18)\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch_xla\n",
    "import torch_xla.debug.metrics as met\n",
    "import torch_xla.distributed.parallel_loader as pl\n",
    "import torch_xla.utils.utils as xu\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.distributed.xla_multiprocessing as xmp\n",
    "import torch_xla.test.test_utils as test_utils\n",
    "\n",
    "\n",
    "class MNIST(nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(MNIST, self).__init__()\n",
    "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "    self.bn1 = nn.BatchNorm2d(10)\n",
    "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "    self.bn2 = nn.BatchNorm2d(20)\n",
    "    self.fc1 = nn.Linear(320, 50)\n",
    "    self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = self.bn1(x)\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "    x = self.bn2(x)\n",
    "    x = torch.flatten(x, 1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = self.fc2(x)\n",
    "    return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "def _train_update(device, x, loss, tracker, writer):\n",
    "  test_utils.print_training_update(\n",
    "      device,\n",
    "      x,\n",
    "      loss.item(),\n",
    "      tracker.rate(),\n",
    "      tracker.global_rate(),\n",
    "      summary_writer=writer)\n",
    "\n",
    "\n",
    "def train_mnist(flags, **kwargs):\n",
    "  torch.manual_seed(1)\n",
    "\n",
    "  if flags.fake_data:\n",
    "    train_loader = xu.SampleGenerator(\n",
    "        data=(torch.zeros(flags.batch_size, 1, 28,\n",
    "                          28), torch.zeros(flags.batch_size,\n",
    "                                           dtype=torch.int64)),\n",
    "        sample_count=60000 // flags.batch_size // xm.xrt_world_size())\n",
    "    test_loader = xu.SampleGenerator(\n",
    "        data=(torch.zeros(flags.batch_size, 1, 28,\n",
    "                          28), torch.zeros(flags.batch_size,\n",
    "                                           dtype=torch.int64)),\n",
    "        sample_count=10000 // flags.batch_size // xm.xrt_world_size())\n",
    "  else:\n",
    "    train_dataset = datasets.MNIST(\n",
    "        os.path.join(flags.datadir, str(xm.get_ordinal())),\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "    test_dataset = datasets.MNIST(\n",
    "        os.path.join(flags.datadir, str(xm.get_ordinal())),\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms.Compose(\n",
    "            [transforms.ToTensor(),\n",
    "             transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "    train_sampler = None\n",
    "    if xm.xrt_world_size() > 1:\n",
    "      train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
    "          train_dataset,\n",
    "          num_replicas=xm.xrt_world_size(),\n",
    "          rank=xm.get_ordinal(),\n",
    "          shuffle=True)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=flags.batch_size,\n",
    "        sampler=train_sampler,\n",
    "        drop_last=flags.drop_last,\n",
    "        shuffle=False if train_sampler else True,\n",
    "        num_workers=flags.num_workers)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=flags.batch_size,\n",
    "        drop_last=flags.drop_last,\n",
    "        shuffle=False,\n",
    "        num_workers=flags.num_workers)\n",
    "\n",
    "  # Scale learning rate to num cores\n",
    "  lr = flags.lr * xm.xrt_world_size()\n",
    "\n",
    "  device = xm.xla_device()\n",
    "  model = MNIST().to(device)\n",
    "  writer = None\n",
    "  if xm.is_master_ordinal():\n",
    "    writer = test_utils.get_summary_writer(flags.logdir)\n",
    "  optimizer = optim.SGD(model.parameters(), lr=lr, momentum=flags.momentum)\n",
    "  loss_fn = nn.NLLLoss()\n",
    "\n",
    "  def train_loop_fn(loader):\n",
    "    tracker = xm.RateTracker()\n",
    "    model.train()\n",
    "    for step, (data, target) in enumerate(loader):\n",
    "      optimizer.zero_grad()\n",
    "      output = model(data)\n",
    "      loss = loss_fn(output, target)\n",
    "      loss.backward()\n",
    "      xm.optimizer_step(optimizer)\n",
    "      tracker.add(flags.batch_size)\n",
    "      if step % flags.log_steps == 0:\n",
    "        xm.add_step_closure(\n",
    "            _train_update,\n",
    "            args=(device, step, loss, tracker, writer),\n",
    "            run_async=FLAGS.async_closures)\n",
    "\n",
    "  def test_loop_fn(loader):\n",
    "    total_samples = 0\n",
    "    correct = 0\n",
    "    model.eval()\n",
    "    for data, target in loader:\n",
    "      output = model(data)\n",
    "      pred = output.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.view_as(pred)).sum()\n",
    "      total_samples += data.size()[0]\n",
    "\n",
    "    accuracy = 100.0 * correct.item() / total_samples\n",
    "    accuracy = xm.mesh_reduce('test_accuracy', accuracy, np.mean)\n",
    "    return accuracy\n",
    "\n",
    "  train_device_loader = pl.MpDeviceLoader(train_loader, device)\n",
    "  test_device_loader = pl.MpDeviceLoader(test_loader, device)\n",
    "  accuracy, max_accuracy = 0.0, 0.0\n",
    "  for epoch in range(1, flags.num_epochs + 1):\n",
    "    xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now()))\n",
    "    train_loop_fn(train_device_loader)\n",
    "    xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))\n",
    "\n",
    "    accuracy = test_loop_fn(test_device_loader)\n",
    "    xm.master_print('Epoch {} test end {}, Accuracy={:.2f}'.format(\n",
    "        epoch, test_utils.now(), accuracy))\n",
    "    max_accuracy = max(accuracy, max_accuracy)\n",
    "    test_utils.write_to_summary(\n",
    "        writer,\n",
    "        epoch,\n",
    "        dict_to_write={'Accuracy/test': accuracy},\n",
    "        write_xla_metrics=True)\n",
    "    if flags.metrics_debug:\n",
    "      xm.master_print(met.metrics_report())\n",
    "\n",
    "  test_utils.close_summary_writer(writer)\n",
    "  xm.master_print('Max Accuracy: {:.2f}%'.format(max_accuracy))\n",
    "  return max_accuracy\n",
    "\n",
    "\n",
    "def _mp_fn(index, flags):\n",
    "  torch.set_default_tensor_type('torch.FloatTensor')\n",
    "  accuracy = train_mnist(flags)\n",
    "  if flags.tidy and os.path.isdir(flags.datadir):\n",
    "    shutil.rmtree(flags.datadir)\n",
    "  if accuracy < flags.target_accuracy:\n",
    "    print('Accuracy {} is below target {}'.format(accuracy,\n",
    "                                                  flags.target_accuracy))\n",
    "    sys.exit(21)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  xmp.spawn(_mp_fn, args=(FLAGS,), nprocs=FLAGS.num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aeb216-d3c7-4c8b-8e8f-9cc9a32db2ac",
   "metadata": {},
   "source": [
    "## Build custom container image with dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb71de-039e-4b80-815f-a253d1070329",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile Dockerfile.pytorch-tpu-mnist\n",
    "\n",
    "FROM gcr.io/tpu-pytorch/xla:r1.12_3.8_tpuvm\n",
    "\n",
    "RUN pip install https://storage.googleapis.com/cloud-tpu-tpuvm-artifacts/wheels/libtpu-nightly/libtpu_nightly-0.1.dev20211015-py3-none-any.whl\n",
    "\n",
    "WORKDIR /\n",
    "COPY train.py /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e806073-7c70-42ad-beea-615970e64203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base container image name\n",
    "DOCKER_ARTIFACT_REPO = 'pytorch-on-tpu-vm'\n",
    "IMAGE_NAME = \"train-mnist\"\n",
    "# IMAGE_URI = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{DOCKER_ARTIFACT_REPO}/{IMAGE_NAME}\"\n",
    "IMAGE_URI = f\"us.gcr.io/{PROJECT_ID}/{DOCKER_ARTIFACT_REPO}/{IMAGE_NAME}\"\n",
    "\n",
    "IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bab3adb-281b-4c00-9658-51b3c0fc4dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Docker repository with your region with the description\n",
    "! gcloud artifacts repositories create {DOCKER_ARTIFACT_REPO} \\\n",
    "    --repository-format=docker \\\n",
    "    --location={REGION} \\\n",
    "    --description=\"PyTorch TPU VM Docker repository\"\n",
    "\n",
    "# verify that your repository was created.\n",
    "! gcloud artifacts repositories list \\\n",
    "    --location={REGION} \\\n",
    "    --filter=\"name~\"{DOCKER_ARTIFACT_REPO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a75a7-d0c9-40b2-99bc-6918c6a071e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac721c86-1e4b-4619-b967-11916d4a306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile cloudbuild.yaml\n",
    "\n",
    "steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: ['build', '-t', '$_IMAGE_URI', '$_FILE_LOCATION', '-f', '$_FILE_LOCATION/Dockerfile.$_DOCKERNAME']\n",
    "images:\n",
    "- '$_IMAGE_URI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b095c2ee-1c89-4858-87b9-e5a258cac87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = './'\n",
    "\n",
    "! gcloud builds submit \\\n",
    "      --region $REGION \\\n",
    "      --config src/cloudbuild.yaml \\\n",
    "      --substitutions _DOCKERNAME=\"pytorch-tpu-mnist\",_IMAGE_URI=$IMAGE_URI,_FILE_LOCATION=$FILE_LOCATION \\\n",
    "      --timeout \"2h\" \\\n",
    "      --machine-type=e2-highcpu-32 \\\n",
    "      --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7154d3d8-7e55-4d20-9605-a4572b9481bb",
   "metadata": {},
   "source": [
    "## Submit training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d498f0-0fa3-4a92-a064-ed67d12692b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Vertex AI SDK\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd667b6-ac74-457e-8efb-78606f4ef2e0",
   "metadata": {},
   "source": [
    "### Using CustomJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d69934c-b16a-4605-933a-ec84b97d36c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "APP_NAME = \"pytorch-train-mnist-tpu\"\n",
    "JOB_NAME = f\"{APP_NAME}-{TIMESTAMP}\"\n",
    "print(f\"JOB_NAME = {JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95db28-c233-439f-9538-f0214cf158df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define worker pool specs\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"cloud-tpu\",\n",
    "            \"accelerator_type\": \"TPU_V2\",\n",
    "            \"accelerator_count\": 8,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"command\": [\"python3\", \"/train.py\"],\n",
    "            \"args\": [],\n",
    "            \"env\": [\n",
    "                {\n",
    "                    \"name\": \"XRT_TPU_CONFIG\",\n",
    "                    \"value\": \"localservice;0;localhost:51011\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bfd12b-2bd8-456b-ad2d-cb92bc69c7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom job\n",
    "job = aiplatform.CustomJob(\n",
    "    display_name=JOB_NAME,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=BUCKET_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceda0b19-0fc8-414c-a03b-ccd17f23a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the job\n",
    "job_response = job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517bc61e-a7d0-4c27-8ef7-18ed2cde8dc6",
   "metadata": {},
   "source": [
    "### Using CustomContainerTrainingJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6d3a59-564c-4eef-9b5a-81007df4059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "APP_NAME = \"pytorch-train-mnist-tpu\"\n",
    "JOB_NAME = f\"{APP_NAME}-{TIMESTAMP}\"\n",
    "print(f\"JOB_NAME = {JOB_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076e7b48-1a27-4e03-9d92-8981cc213fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the job with container image spec\n",
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=JOB_NAME, \n",
    "    container_uri=IMAGE_URI,\n",
    "    command=[\"python3\", \"/train.py\"],\n",
    "    staging_bucket=BUCKET_URI\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25bc7b2-5382-4d1b-83f0-d70fad83d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the job\n",
    "job_response = job.run(\n",
    "    replica_count=1,\n",
    "    machine_type='cloud-tpu',\n",
    "    accelerator_type='TPU_V2',\n",
    "    accelerator_count=8,\n",
    "    base_output_dir=f'{BUCKET_URI}/tpu-experiments/{APP_NAME}/'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "tpu-gke",
   "name": "common-cu110.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m93"
  },
  "kernelspec": {
   "display_name": "tpu-gke",
   "language": "python",
   "name": "tpu-gke"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
